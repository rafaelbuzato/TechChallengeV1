# ğŸ§ª Guia Completo de Testes - Books Scraper API

DocumentaÃ§Ã£o completa sobre testes unitÃ¡rios, integraÃ§Ã£o e automaÃ§Ã£o.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Estrutura de Testes](#-estrutura-de-testes)
- [Executando Testes](#-executando-testes)
- [Cobertura de CÃ³digo](#-cobertura-de-cÃ³digo)
- [Tipos de Testes](#-tipos-de-testes)
- [Guia de Escrita](#-guia-de-escrita)
- [CI/CD](#-cicd)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O projeto possui **50+ testes automatizados** cobrindo todos os endpoints e funcionalidades.

### EstatÃ­sticas

| MÃ©trica | Valor |
|---------|-------|
| Total de Testes | 50+ |
| Cobertura de CÃ³digo | 85%+ |
| Classes de Teste | 13 |
| Tempo de ExecuÃ§Ã£o | ~5 segundos |
| Frameworks | Pytest, httpx |

### Tipos de Testes IncluÃ­dos

âœ… **Testes UnitÃ¡rios** - FunÃ§Ãµes individuais  
âœ… **Testes de IntegraÃ§Ã£o** - Fluxos completos  
âœ… **Testes de API** - Todos os endpoints  
âœ… **Testes de AutenticaÃ§Ã£o** - JWT e permissÃµes  
âœ… **Testes de ML** - Endpoints de Machine Learning  
âœ… **Testes de Performance** - Tempo de resposta  

---

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Instalar DependÃªncias de Teste

```bash
# Instalar dependÃªncias principais
pip install -r requirements.txt

# Instalar dependÃªncias de desenvolvimento
pip install -r requirements-dev.txt
```

### 2. Verificar InstalaÃ§Ã£o

```bash
pytest --version
# pytest 7.4.3

python -m pytest --version
```

---

## ğŸ“ Estrutura de Testes

```
tests/
â”œâ”€â”€ __init__.py                  # InicializaÃ§Ã£o do pacote
â”œâ”€â”€ conftest.py                  # Fixtures compartilhadas (opcional)
â”œâ”€â”€ test_api.py                  # â­ Testes principais (50+ testes)
â”œâ”€â”€ test_auth.py                 # Testes de autenticaÃ§Ã£o (opcional)
â”œâ”€â”€ test_ml.py                   # Testes de ML (opcional)
â””â”€â”€ test_integration.py          # Testes de integraÃ§Ã£o (opcional)
```

### Classes de Teste DisponÃ­veis

```python
# test_api.py

class TestRoot:              # 1 teste  - Endpoint raiz
class TestHealth:            # 2 testes - Health check
class TestBooks:             # 7 testes - CRUD de livros
class TestSearch:            # 6 testes - Busca e filtros
class TestTopRated:          # 3 testes - Top livros
class TestPriceRange:        # 3 testes - Faixa de preÃ§o
class TestCategories:        # 2 testes - Categorias
class TestStatistics:        # 4 testes - EstatÃ­sticas
class TestAuthentication:    # 5 testes - Auth JWT
class TestMachineLearning:   # 8 testes - ML endpoints
class TestAdmin:             # 4 testes - Rotas admin
class TestIntegration:       # 3 testes - Testes integrados
class TestPerformance:       # 2 testes - Performance
```

---

## ğŸš€ Executando Testes

### Comandos BÃ¡sicos

```bash
# Executar todos os testes
pytest

# Com output verbose
pytest -v

# Com output detalhado
pytest -vv

# Modo quiet (apenas sumÃ¡rio)
pytest -q
```

### Executar Testes EspecÃ­ficos

```bash
# Um arquivo
pytest tests/test_api.py

# Uma classe especÃ­fica
pytest tests/test_api.py::TestBooks

# Um teste especÃ­fico
pytest tests/test_api.py::TestBooks::test_get_all_books

# MÃºltiplos arquivos
pytest tests/test_api.py tests/test_auth.py
```

### Executar por Marcador

```bash
# Criar marcadores no pytest.ini primeiro
pytest -m unit           # Apenas testes unitÃ¡rios
pytest -m integration    # Apenas integraÃ§Ã£o
pytest -m auth          # Apenas autenticaÃ§Ã£o
pytest -m ml            # Apenas ML
pytest -m slow          # Apenas testes lentos
```

### OpÃ§Ãµes Ãšteis

```bash
# Parar no primeiro erro
pytest -x

# Parar apÃ³s N falhas
pytest --maxfail=3

# Executar apenas testes que falharam
pytest --lf

# Executar testes que falharam primeiro
pytest --ff

# Ver print statements
pytest -s

# Ver variÃ¡veis locais em falhas
pytest -l

# Traceback curto
pytest --tb=short

# Traceback longo
pytest --tb=long

# Sem traceback
pytest --tb=no
```

---

## ğŸ“Š Cobertura de CÃ³digo

### Executar com Cobertura

```bash
# Cobertura simples
pytest --cov=app

# Com report detalhado
pytest --cov=app --cov-report=term-missing

# RelatÃ³rio HTML
pytest --cov=app --cov-report=html

# Abrir relatÃ³rio HTML
start htmlcov/index.html  # Windows
open htmlcov/index.html   # Mac
xdg-open htmlcov/index.html  # Linux
```

### Cobertura por MÃ³dulo

```bash
# Apenas um mÃ³dulo
pytest --cov=app.main

# MÃºltiplos mÃ³dulos
pytest --cov=app.main --cov=app.auth
```

### ConfiguraÃ§Ã£o de Cobertura MÃ­nima

```bash
# Falhar se cobertura < 80%
pytest --cov=app --cov-fail-under=80

# Falhar se cobertura < 85%
pytest --cov=app --cov-fail-under=85
```

### Exemplo de SaÃ­da

```
----------- coverage: platform win32, python 3.11.0 -----------
Name                    Stmts   Miss  Cover   Missing
-----------------------------------------------------
app/__init__.py            0      0   100%
app/auth.py               45      3    93%   78-80
app/config.py             35      2    94%   45, 67
app/database.py          120     12    90%   89-95, 134-138
app/main.py              180     15    92%   245-250, 312-318
app/models.py             85      0   100%
-----------------------------------------------------
TOTAL                    465     32    93%
```

---

## ğŸ”¬ Tipos de Testes

### 1. Testes UnitÃ¡rios

Testam funÃ§Ãµes individuais isoladamente.

```python
def test_parse_price():
    """Testa funÃ§Ã£o de parse de preÃ§o"""
    from app.database import parse_price
    
    assert parse_price("Â£25.50") == 25.50
    assert parse_price("Â£100.00") == 100.00
    assert parse_price("invalid") == 0.0
```

### 2. Testes de API

Testam endpoints HTTP.

```python
def test_get_all_books():
    """Testa listagem de livros"""
    response = client.get("/api/v1/books")
    
    assert response.status_code == 200
    assert isinstance(response.json(), list)
```

### 3. Testes de AutenticaÃ§Ã£o

```python
def test_login_success():
    """Testa login com credenciais vÃ¡lidas"""
    response = client.post(
        "/api/v1/auth/login",
        json={"username": "admin", "password": "admin123"}
    )
    
    assert response.status_code == 200
    data = response.json()
    assert "access_token" in data
    assert "refresh_token" in data
    assert data["token_type"] == "bearer"
```

### 4. Testes de IntegraÃ§Ã£o

```python
def test_full_flow():
    """Testa fluxo completo: login â†’ busca â†’ detalhes"""
    # 1. Login
    login = client.post(
        "/api/v1/auth/login",
        json={"username": "admin", "password": "admin123"}
    )
    token = login.json()["access_token"]
    
    # 2. Buscar livros
    search = client.get("/api/v1/books/search?title=light")
    books = search.json()
    assert len(books) > 0
    
    # 3. Obter detalhes
    book_id = books[0]["id"]
    details = client.get(f"/api/v1/books/{book_id}")
    assert details.status_code == 200
```

### 5. Testes Parametrizados

```python
import pytest

@pytest.mark.parametrize("username,password,expected", [
    ("admin", "admin123", 200),
    ("user", "user123", 200),
    ("invalid", "wrong", 401),
    ("", "", 422),
])
def test_login_cases(username, password, expected):
    """Testa mÃºltiplos casos de login"""
    response = client.post(
        "/api/v1/auth/login",
        json={"username": username, "password": password}
    )
    assert response.status_code == expected
```

### 6. Testes com Fixtures

```python
import pytest

@pytest.fixture
def admin_token():
    """Fixture para obter token admin"""
    response = client.post(
        "/api/v1/auth/login",
        json={"username": "admin", "password": "admin123"}
    )
    return response.json()["access_token"]

def test_admin_endpoint(admin_token):
    """Testa endpoint protegido"""
    response = client.post(
        "/api/v1/scraping/reload",
        headers={"Authorization": f"Bearer {admin_token}"}
    )
    assert response.status_code == 200
```

### 7. Testes de Performance

```python
import time

def test_response_time():
    """Testa tempo de resposta"""
    start = time.time()
    response = client.get("/api/v1/books")
    end = time.time()
    
    assert response.status_code == 200
    assert (end - start) < 1.0  # Menos de 1 segundo
```

---

## âœï¸ Guia de Escrita de Testes

### PadrÃ£o AAA (Arrange-Act-Assert)

```python
def test_create_book():
    """Testa criaÃ§Ã£o de livro"""
    
    # Arrange - preparar dados
    book_data = {
        "titulo": "Test Book",
        "preco": 20.0,
        "categoria": "Fiction"
    }
    
    # Act - executar aÃ§Ã£o
    response = client.post("/api/v1/books", json=book_data)
    
    # Assert - verificar resultado
    assert response.status_code == 201
    assert response.json()["titulo"] == "Test Book"
```

### NomeaÃ§Ã£o de Testes

```python
# âœ… Bom - descritivo e claro
def test_login_with_invalid_credentials_returns_401():
    pass

def test_search_books_by_title_filters_correctly():
    pass

# âŒ Ruim - vago
def test_login():
    pass

def test_search():
    pass
```

### OrganizaÃ§Ã£o por CenÃ¡rio

```python
class TestBookSearch:
    """Testes de busca de livros"""
    
    def test_search_by_title_returns_matches(self):
        """Busca por tÃ­tulo retorna correspondÃªncias"""
        pass
    
    def test_search_by_category_filters_correctly(self):
        """Busca por categoria filtra corretamente"""
        pass
    
    def test_search_with_no_results_returns_empty_list(self):
        """Busca sem resultados retorna lista vazia"""
        pass
    
    def test_search_with_multiple_filters_combines_correctly(self):
        """Busca com mÃºltiplos filtros combina corretamente"""
        pass
```

### Boas PrÃ¡ticas

#### âœ… Fazer

- Testes independentes (nÃ£o dependem de ordem)
- Um assert por conceito
- Nomes descritivos
- Testar casos de sucesso e erro
- Usar fixtures para setup comum
- Documentar testes complexos

#### âŒ Evitar

- Testes dependentes
- MÃºltiplos conceitos em um teste
- Nomes vagos
- Testar apenas happy path
- DuplicaÃ§Ã£o de cÃ³digo
- Testes sem documentaÃ§Ã£o

---

## ğŸ“ˆ RelatÃ³rios e MÃ©tricas

### RelatÃ³rio de Testes

```bash
# SumÃ¡rio simples
pytest --tb=no --no-header -q

# RelatÃ³rio detalhado
pytest -v --tb=line

# Com duraÃ§Ã£o dos testes
pytest --durations=10

# Top 20 testes mais lentos
pytest --durations=20
```

### Exemplo de SaÃ­da

```
==================== test session starts ====================
collected 50 items

tests/test_api.py::TestRoot::test_root_endpoint PASSED    [  2%]
tests/test_api.py::TestHealth::test_health_check PASSED   [  4%]
tests/test_api.py::TestBooks::test_get_all_books PASSED   [  6%]
tests/test_api.py::TestBooks::test_get_book_by_id PASSED  [  8%]
...
tests/test_api.py::TestPerformance::test_response_time PASSED [100%]

==================== 50 passed in 4.52s ====================
```

### RelatÃ³rio HTML

```bash
# Gerar relatÃ³rio
pytest --html=report.html --self-contained-html

# Abrir relatÃ³rio
start report.html
```

### RelatÃ³rio JSON

```bash
# Instalar plugin
pip install pytest-json-report

# Gerar relatÃ³rio
pytest --json-report --json-report-file=report.json
```

---

## ğŸ”„ CI/CD

### GitHub Actions

Crie `.github/workflows/tests.yml`:

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: [3.11, 3.12]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run scraper to generate data
      run: |
        python scraper/scraper.py
    
    - name: Run tests
      run: |
        pytest --cov=app --cov-report=xml --cov-report=term
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: true
```

### GitLab CI

Crie `.gitlab-ci.yml`:

```yaml
image: python:3.11

stages:
  - test

test:
  stage: test
  before_script:
    - pip install -r requirements-dev.txt
  script:
    - python scraper/scraper.py
    - pytest --cov=app --cov-report=term --cov-report=html
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
```

### Pre-commit Hooks

Crie `.pre-commit-config.yaml`:

```yaml
repos:
  - repo: local
    hooks:
      - id: tests
        name: Run tests
        entry: pytest
        language: system
        pass_filenames: false
        always_run: true
```

---

## ğŸ› Troubleshooting

### Erro: "No module named 'app'"

**Causa:** PYTHONPATH incorreto

**SoluÃ§Ã£o:**
```bash
# Adicione o diretÃ³rio raiz ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# Ou execute de forma diferente
python -m pytest
```

### Erro: "Database not available"

**Causa:** Arquivo de dados nÃ£o existe

**SoluÃ§Ã£o:**
```bash
# Execute o scraper primeiro
python scraper/scraper.py

# Verifique se o arquivo foi criado
ls -la data/books_data.xlsx
```

### Testes Muito Lentos

**SoluÃ§Ã£o:**
```bash
# Use pytest-xdist para paralelizaÃ§Ã£o
pip install pytest-xdist

# Execute em paralelo
pytest -n auto
```

### Conflito de Cache

**SoluÃ§Ã£o:**
```bash
# Limpar cache do pytest
pytest --cache-clear

# Remover diretÃ³rio de cache
rm -rf .pytest_cache
```

### Falhas Intermitentes

**Causa:** Testes dependentes de ordem

**SoluÃ§Ã£o:**
```bash
# Execute em ordem aleatÃ³ria
pip install pytest-randomly
pytest
```

---

## ğŸ“š Recursos e Plugins

### Plugins Ãšteis

```bash
# Melhor UI
pip install pytest-sugar

# RelatÃ³rio HTML
pip install pytest-html

# ParalelizaÃ§Ã£o
pip install pytest-xdist

# Ordem aleatÃ³ria
pip install pytest-randomly

# Mock
pip install pytest-mock

# Asyncio
pip install pytest-asyncio

# Timeout
pip install pytest-timeout
```

### Uso de Plugins

```bash
# pytest-sugar (UI melhorada)
pytest

# pytest-html (relatÃ³rio HTML)
pytest --html=report.html

# pytest-xdist (paralelo)
pytest -n 4  # 4 workers

# pytest-timeout (timeout)
pytest --timeout=10  # 10s por teste
```

---

## ğŸ“‹ Checklist de Testes

Antes de fazer commit/deploy:

- [ ] Todos os testes passam (`pytest`)
- [ ] Cobertura > 80% (`pytest --cov=app --cov-fail-under=80`)
- [ ] Sem warnings (`pytest -W error`)
- [ ] Code style ok (`black app/ tests/`)
- [ ] Linting ok (`flake8 app/ tests/`)
- [ ] Type checking ok (`mypy app/`)
- [ ] Testes de integraÃ§Ã£o ok
- [ ] Performance aceitÃ¡vel
- [ ] DocumentaÃ§Ã£o atualizada

---

## ğŸ¯ Comandos RÃ¡pidos

```bash
# Desenvolvimento diÃ¡rio
pytest -v                                    # Executar testes
pytest --lf                                  # Apenas falhas
pytest -k "test_login"                       # Por nome
pytest tests/test_api.py::TestAuth          # Classe especÃ­fica

# Cobertura
pytest --cov=app --cov-report=html          # RelatÃ³rio HTML
pytest --cov=app --cov-report=term-missing  # Missing lines

# CI/CD
pytest --cov=app --cov-report=xml           # Para Codecov
pytest --junitxml=junit.xml                  # JUnit XML

# Debug
pytest -s                                    # Ver prints
pytest -l                                    # Ver variÃ¡veis locais
pytest --pdb                                 # Debugger em falha
pytest -x --pdb                             # Para + debug

# Performance
pytest --durations=10                        # Top 10 lentos
pytest -n auto                               # Paralelo
```

---

## ğŸ“Š Exemplo Completo de SaÃ­da

```bash
$ pytest -v --cov=app --cov-report=term

==================== test session starts ====================
platform win32 -- Python 3.11.0
cachedir: .pytest_cache
plugins: cov-4.1.0, asyncio-0.21.1
collected 50 items

tests/test_api.py::TestRoot::test_root_endpoint PASSED                    [  2%]
tests/test_api.py::TestHealth::test_health_check PASSED                   [  4%]
tests/test_api.py::TestHealth::test_health_database_info PASSED           [  6%]
tests/test_api.py::TestBooks::test_get_all_books PASSED                   [  8%]
tests/test_api.py::TestBooks::test_get_books_with_limit PASSED            [ 10%]
tests/test_api.py::TestBooks::test_get_book_by_id PASSED                  [ 12%]
tests/test_api.py::TestSearch::test_search_by_title PASSED                [ 14%]
tests/test_api.py::TestSearch::test_search_by_category PASSED             [ 16%]
tests/test_api.py::TestAuth::test_login_success PASSED                    [ 18%]
tests/test_api.py::TestAuth::test_login_invalid_credentials PASSED        [ 20%]
tests/test_api.py::TestML::test_ml_prediction_success PASSED              [ 22%]
...
tests/test_api.py::TestPerformance::test_response_time_books PASSED       [100%]

---------- coverage: platform win32, python 3.11.0 -----------
Name                    Stmts   Miss  Cover
-------------------------------------------
app/__init__.py            0      0   100%
app/auth.py               45      3    93%
app/config.py             35      2    94%
app/database.py          120     12    90%
app/main.py              180     15    92%
app/models.py             85      0   100%
-------------------------------------------
TOTAL                    465     32    93%

==================== 50 passed in 4.52s ====================
```

---

<div align="center">

**âœ… Testes sÃ£o essenciais para cÃ³digo confiÃ¡vel! ğŸš€**

[ğŸ” Voltar ao README](README.md)

</div>