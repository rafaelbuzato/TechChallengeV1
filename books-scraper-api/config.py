"""
Configura√ß√µes da Aplica√ß√£o
===========================

"""

import os
from pathlib import Path
from dotenv import load_dotenv

# Carrega vari√°veis do arquivo .env (se existir)
load_dotenv()

# ==================== DIRET√ìRIOS ====================

# Diret√≥rio base do projeto (raiz)
BASE_DIR = Path(__file__).parent

# Diret√≥rio de dados
DATA_DIR = BASE_DIR / "data"

# Diret√≥rio de logs
LOGS_DIR = BASE_DIR / "logs"

# Cria diret√≥rios se n√£o existirem
DATA_DIR.mkdir(exist_ok=True)
LOGS_DIR.mkdir(exist_ok=True)


# ==================== API ====================

# Configura√ß√µes do servidor
API_HOST = os.getenv("API_HOST", "0.0.0.0")
API_PORT = int(os.getenv("API_PORT", 8000))
DEBUG = os.getenv("DEBUG", "True").lower() == "true"

# Informa√ß√µes da API
PROJECT_NAME = "Books Scraper API"
VERSION = "1.0.0"
DESCRIPTION = "API RESTful para consultar livros com autentica√ß√£o JWT"

# Prefixo da API
API_V1_PREFIX = "/api/v1"


# ==================== SEGURAN√áA ====================

# Chave secreta para JWT (MUDE EM PRODU√á√ÉO!)
SECRET_KEY = os.getenv(
    "SECRET_KEY",
    "change-this-secret-key-in-production-use-a-random-string"
)

# Algoritmo de criptografia JWT
ALGORITHM = "HS256"

# Tempo de expira√ß√£o dos tokens
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))
REFRESH_TOKEN_EXPIRE_DAYS = int(os.getenv("REFRESH_TOKEN_EXPIRE_DAYS", 7))


# ==================== DADOS ====================

# Arquivo de dados Excel
DATA_FILE = DATA_DIR / "books_data.xlsx"

# Arquivo de dados CSV (opcional)
CSV_FILE = DATA_DIR / "books_data.csv"

# Tempo de cache em segundos (10 minutos)
CACHE_TIMEOUT = int(os.getenv("CACHE_TIMEOUT_SECONDS", 600))


# ==================== WEB SCRAPING ====================

# URL alvo para scraping
SCRAPER_URL = os.getenv("SCRAPER_TARGET_URL", "https://books.toscrape.com/")

# N√∫mero m√°ximo de p√°ginas para scraping
SCRAPER_MAX_PAGES = int(os.getenv("SCRAPER_MAX_PAGES", 50))

# Delay entre requisi√ß√µes (segundos)
SCRAPER_DELAY = float(os.getenv("SCRAPER_DELAY", 0.5))

# User-Agent para requisi√ß√µes
SCRAPER_USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"

# Timeout para requisi√ß√µes (segundos)
SCRAPER_TIMEOUT = int(os.getenv("SCRAPER_TIMEOUT", 10))

# Caminho do script do scraper
SCRAPER_SCRIPT = BASE_DIR / "scraper" / "scraper.py"


# ==================== CORS ====================

# Origens permitidas para CORS
# Em produ√ß√£o, especifique dom√≠nios espec√≠ficos
ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://localhost:8080",
    "http://127.0.0.1:3000",
    "http://127.0.0.1:8080",
]

# Em desenvolvimento, permite todas as origens
if DEBUG:
    ALLOWED_ORIGINS = ["*"]


# ==================== LOGGING ====================

# N√≠vel de log (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")

# Formato do log
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Arquivo de log
LOG_FILE = LOGS_DIR / "app.log"


# ==================== PAGINA√á√ÉO ====================

# Limite padr√£o de resultados
DEFAULT_PAGE_LIMIT = 100

# Limite m√°ximo de resultados por p√°gina
MAX_PAGE_LIMIT = 1000


# ==================== VALIDA√á√ïES ====================

def validate_config():
    """
    Valida as configura√ß√µes cr√≠ticas
    Levanta exce√ß√µes se houver problemas
    """
    errors = []
    
    # Valida SECRET_KEY em produ√ß√£o
    if not DEBUG and SECRET_KEY == "change-this-secret-key-in-production-use-a-random-string":
        errors.append("‚ö†Ô∏è  SECRET_KEY padr√£o detectada! Altere em produ√ß√£o!")
    
    # Valida diret√≥rio de dados
    if not DATA_DIR.exists():
        errors.append(f"‚ö†Ô∏è  Diret√≥rio de dados n√£o existe: {DATA_DIR}")
    
    # Valida arquivo de dados
    if not DATA_FILE.exists():
        print(f"‚ö†Ô∏è  Arquivo de dados n√£o encontrado: {DATA_FILE}")
        print("üí° Execute o scraper primeiro: python scraper/scraper.py")
    
    # Exibe avisos
    if errors:
        print("\n" + "="*60)
        print("‚ö†Ô∏è  AVISOS DE CONFIGURA√á√ÉO:")
        for error in errors:
            print(f"   {error}")
        print("="*60 + "\n")


# ==================== INFORMA√á√ïES DO SISTEMA ====================

def get_system_info() -> dict:
    """
    Retorna informa√ß√µes sobre a configura√ß√£o atual
    √ötil para debugging
    """
    return {
        "project_name": PROJECT_NAME,
        "version": VERSION,
        "debug": DEBUG,
        "api_host": API_HOST,
        "api_port": API_PORT,
        "data_file": str(DATA_FILE),
        "data_file_exists": DATA_FILE.exists(),
        "cache_timeout": CACHE_TIMEOUT,
        "log_level": LOG_LEVEL,
    }


# Executa valida√ß√£o ao importar
validate_config()


# ==================== EXPORTA√á√ÉO ====================

__all__ = [
    # Diret√≥rios
    "BASE_DIR",
    "DATA_DIR",
    "LOGS_DIR",
    
    # API
    "API_HOST",
    "API_PORT",
    "DEBUG",
    "PROJECT_NAME",
    "VERSION",
    "DESCRIPTION",
    "API_V1_PREFIX",
    
    # Seguran√ßa
    "SECRET_KEY",
    "ALGORITHM",
    "ACCESS_TOKEN_EXPIRE_MINUTES",
    "REFRESH_TOKEN_EXPIRE_DAYS",
    
    # Dados
    "DATA_FILE",
    "CSV_FILE",
    "CACHE_TIMEOUT",
    
    # Scraper
    "SCRAPER_URL",
    "SCRAPER_MAX_PAGES",
    "SCRAPER_DELAY",
    "SCRAPER_USER_AGENT",
    "SCRAPER_TIMEOUT",
    "SCRAPER_SCRIPT",
    
    # CORS
    "ALLOWED_ORIGINS",
    
    # Logging
    "LOG_LEVEL",
    "LOG_FORMAT",
    "LOG_FILE",
    
    # Pagina√ß√£o
    "DEFAULT_PAGE_LIMIT",
    "MAX_PAGE_LIMIT",
    
    # Fun√ß√µes
    "validate_config",
    "get_system_info",
]